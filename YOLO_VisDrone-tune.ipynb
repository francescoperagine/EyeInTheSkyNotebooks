{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/francescoperagine/EyeInTheSkyNotebooks/blob/main/EyeInTheSky_YOLO_VisDrone.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "JFSp9IV98xBU"
      },
      "outputs": [],
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "\n",
        "!pip install loguru==0.7.3 \\\n",
        "             tqdm==4.67.1 \\\n",
        "             typer==0.15.1 \\\n",
        "             ultralytics==8.3.78 \\\n",
        "             wandb==0.19.6 \\\n",
        "             ray==2.42.1 \\\n",
        "             matplotlib==3.10.0 \\\n",
        "             ultralytics \"ray[tune]\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!wget https://github.com/Dao-AILab/flash-attention/releases/download/v2.7.3/flash_attn-2.7.3+cu11torch2.2cxx11abiFALSE-cp311-cp311-linux_x86_64.whl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TGW0ki2jBe62"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata, files\n",
        "from loguru import logger\n",
        "from pathlib import Path\n",
        "from ray import tune\n",
        "from ultralytics import YOLO, checks, settings\n",
        "import os\n",
        "import torch\n",
        "import typer\n",
        "import wandb\n",
        "import yaml\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "app = typer.Typer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ProjectConfig:\n",
        "    \"\"\"Singleton class for managing project configuration and secrets.\"\"\"\n",
        "    _instance = None\n",
        "    \n",
        "    def __new__(cls):\n",
        "        if cls._instance is None:\n",
        "            cls._instance = super().__new__(cls)\n",
        "        return cls._instance\n",
        "    \n",
        "    @staticmethod\n",
        "    def get_config(config_file: str) -> dict:\n",
        "        \"\"\"Load and return configuration from YAML file.\"\"\"\n",
        "        with open(config_file, \"r\") as f:\n",
        "            return yaml.safe_load(f)\n",
        "    \n",
        "    @staticmethod\n",
        "    def get_device() -> str:\n",
        "        try:\n",
        "            return 0 if torch.cuda.is_available() else \"cpu\"\n",
        "        except Exception as e:\n",
        "            print(f\"Error setting device: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def prepare_tune_config(config):\n",
        "    \"\"\"Prepare tune configuration for YOLO tune() method.\"\"\"\n",
        "    tune_config = config[\"tune\"].copy()\n",
        "    \n",
        "    # Convert parameters to proper tune search space\n",
        "    space_config = {}\n",
        "    for param, value in tune_config[\"space\"].items():\n",
        "        if isinstance(value, list):\n",
        "            # For discrete choices like batch_size\n",
        "            space_config[param] = tune.choice(value)\n",
        "        elif isinstance(value, dict) and \"min\" in value and \"max\" in value:\n",
        "            # For continuous ranges using tune.uniform\n",
        "            space_config[param] = tune.uniform(value[\"min\"], value[\"max\"])\n",
        "    \n",
        "    # Remove space from main config\n",
        "    tune_config.pop(\"space\")\n",
        "    \n",
        "    return tune_config, space_config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "config = ProjectConfig.get_config(\"config.yaml\")\n",
        "device = ProjectConfig.get_device()\n",
        "\n",
        "wandb.login(key=userdata.get(\"WANDB_API_KEY\"))\n",
        "settings.update({\"wandb\": True})\n",
        "\n",
        "logger.info(\"Performing training for model...\")\n",
        "logger.info(checks())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = YOLO(f\"{config['model_name']}.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare tune and space configurations\n",
        "tune_config, space_config = prepare_tune_config(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run tuning with space parameter separate\n",
        "result_grid = model.tune(\n",
        "    data=f\"{config['dataset_name']}.yaml\",\n",
        "    device=device,\n",
        "    space=space_config,\n",
        "    use_ray=True,\n",
        "    group=f\"{config['model_name']}-tune\",\n",
        "    **tune_config\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i, result in enumerate(result_grid):\n",
        "    print(f\"Trial #{i}: Configuration: {result.config}, Last Reported Metrics: {result.metrics}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i, result in enumerate(result_grid):\n",
        "    plt.plot(\n",
        "        result.metrics_dataframe[\"training_iteration\"],\n",
        "        result.metrics_dataframe[\"mean_accuracy\"],\n",
        "        label=f\"Trial {i}\",\n",
        "    )\n",
        "\n",
        "plt.xlabel(\"Training Iterations\")\n",
        "plt.ylabel(\"Mean Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyPSnQNh+A1RHvSjyjA2RYmk",
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
